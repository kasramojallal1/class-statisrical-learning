{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Learning HW3\n",
    "\n",
    "Kasra Mojallal 110124782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data with GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 10:33:23.059287: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use California Dataset as a regression problem\n",
    "# It has 8 features\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "          37.88      , -122.23      ],\n",
       "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "          37.86      , -122.22      ],\n",
       "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "          37.85      , -122.24      ],\n",
       "       ...,\n",
       "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "          39.43      , -121.22      ],\n",
       "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "          39.43      , -121.32      ],\n",
       "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "          39.37      , -121.24      ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Generator\n",
    "# The Generator will generate 9 features, 8 relating to the X values\n",
    "# the last one would be the y\n",
    "generator = models.Sequential()\n",
    "generator.add(layers.Dense(128, input_dim=50, activation='relu'))\n",
    "generator.add(layers.Dense(256, activation='relu'))\n",
    "generator.add(layers.Dense(9, activation='linear'))\n",
    "\n",
    "# The Discriminator\n",
    "discriminator = models.Sequential()\n",
    "discriminator.add(layers.Dense(256, input_dim=9, activation='relu'))\n",
    "discriminator.add(layers.Dense(128, activation='relu'))\n",
    "discriminator.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the GAN model\n",
    "discriminator.trainable = False\n",
    "gan_input = layers.Input(shape=(50,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = models.Model(gan_input, gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    return (data - np.min(data, axis=0)) / (np.max(data, axis=0) - np.min(data, axis=0))\n",
    "\n",
    "def preprocess_data(X, y):\n",
    "    X_normalized = normalize_data(X)\n",
    "    y_normalized = normalize_data(y.reshape(-1, 1))\n",
    "    return X_normalized, y_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Discriminator and the GAN\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizers.Adam(learning_rate=0.0002))\n",
    "gan.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizers.Adam(learning_rate=0.0002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "Epoch: 0, Discriminator Loss: 73.0049819946289, GAN Loss: 0.7152770757675171\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 1, Discriminator Loss: 87.5365219116211, GAN Loss: 0.7110215425491333\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 2, Discriminator Loss: 57.251102447509766, GAN Loss: 0.7050318717956543\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch: 3, Discriminator Loss: 72.19908142089844, GAN Loss: 0.7039123773574829\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch: 4, Discriminator Loss: 80.90995788574219, GAN Loss: 0.7036734223365784\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch: 5, Discriminator Loss: 67.80726623535156, GAN Loss: 0.7017752528190613\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 6, Discriminator Loss: 68.39640808105469, GAN Loss: 0.7003308534622192\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 7, Discriminator Loss: 90.03854370117188, GAN Loss: 0.6957268118858337\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch: 8, Discriminator Loss: 83.80489349365234, GAN Loss: 0.6969507932662964\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 9, Discriminator Loss: 73.7119369506836, GAN Loss: 0.6951723098754883\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 10, Discriminator Loss: 62.18650436401367, GAN Loss: 0.6901654601097107\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 11, Discriminator Loss: 65.37095642089844, GAN Loss: 0.6920673251152039\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch: 12, Discriminator Loss: 84.71754455566406, GAN Loss: 0.6859445571899414\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch: 13, Discriminator Loss: 71.63494873046875, GAN Loss: 0.689170777797699\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Epoch: 14, Discriminator Loss: 74.9627685546875, GAN Loss: 0.6855747699737549\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch: 15, Discriminator Loss: 84.69979858398438, GAN Loss: 0.6858279705047607\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 16, Discriminator Loss: 82.79203796386719, GAN Loss: 0.6802231073379517\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 17, Discriminator Loss: 79.47391510009766, GAN Loss: 0.6782016754150391\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 18, Discriminator Loss: 84.49456787109375, GAN Loss: 0.6789640784263611\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 19, Discriminator Loss: 82.70440673828125, GAN Loss: 0.6760478019714355\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 20, Discriminator Loss: 76.11456298828125, GAN Loss: 0.671831488609314\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 21, Discriminator Loss: 66.05012512207031, GAN Loss: 0.6693757772445679\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 22, Discriminator Loss: 91.74359130859375, GAN Loss: 0.6652640104293823\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 23, Discriminator Loss: 74.15553283691406, GAN Loss: 0.6631836891174316\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 24, Discriminator Loss: 89.0528564453125, GAN Loss: 0.6610550880432129\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 25, Discriminator Loss: 162.63845825195312, GAN Loss: 0.6608854532241821\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 26, Discriminator Loss: 64.45704650878906, GAN Loss: 0.6562789082527161\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 27, Discriminator Loss: 64.32858276367188, GAN Loss: 0.6533177495002747\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 28, Discriminator Loss: 97.8790054321289, GAN Loss: 0.6521245241165161\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 29, Discriminator Loss: 70.03358459472656, GAN Loss: 0.6533492803573608\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 30, Discriminator Loss: 98.74497985839844, GAN Loss: 0.6486552357673645\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 31, Discriminator Loss: 64.68799591064453, GAN Loss: 0.6493980288505554\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 32, Discriminator Loss: 73.98104858398438, GAN Loss: 0.6499834060668945\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 33, Discriminator Loss: 77.03302001953125, GAN Loss: 0.6387445330619812\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 34, Discriminator Loss: 78.02872467041016, GAN Loss: 0.6367014646530151\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 35, Discriminator Loss: 67.70277404785156, GAN Loss: 0.6383548378944397\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 36, Discriminator Loss: 82.51689147949219, GAN Loss: 0.6299211382865906\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 37, Discriminator Loss: 63.660972595214844, GAN Loss: 0.6236410140991211\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Epoch: 38, Discriminator Loss: 77.0609359741211, GAN Loss: 0.6220846176147461\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 39, Discriminator Loss: 93.43797302246094, GAN Loss: 0.6223368644714355\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 40, Discriminator Loss: 78.25462341308594, GAN Loss: 0.6202566623687744\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch: 41, Discriminator Loss: 76.17356872558594, GAN Loss: 0.6156503558158875\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 42, Discriminator Loss: 71.34229278564453, GAN Loss: 0.6130834817886353\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 43, Discriminator Loss: 70.03597259521484, GAN Loss: 0.6066141724586487\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Epoch: 44, Discriminator Loss: 76.21159362792969, GAN Loss: 0.6114435195922852\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 45, Discriminator Loss: 75.18254089355469, GAN Loss: 0.6046402454376221\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Epoch: 46, Discriminator Loss: 72.40467834472656, GAN Loss: 0.6091326475143433\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 47, Discriminator Loss: 75.9456787109375, GAN Loss: 0.5935923457145691\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 48, Discriminator Loss: 73.64950561523438, GAN Loss: 0.6034075617790222\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Epoch: 49, Discriminator Loss: 76.45182800292969, GAN Loss: 0.5967267751693726\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "        real_samples_X = X[idx]\n",
    "        real_samples_y = y[idx]\n",
    "        real_samples_y = real_samples_y.reshape(-1, 1)\n",
    "\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, 50))\n",
    "        generated_samples = generator.predict(noise)\n",
    "\n",
    "        X_batch = np.concatenate([real_samples_X, generated_samples[:, :8]], axis=0)\n",
    "        y_batch = np.concatenate([real_samples_y, generated_samples[:, 8:]], axis=0)\n",
    "        \n",
    "        Xy = np.concatenate([X_batch, y_batch], axis=1)\n",
    "\n",
    "        y_discriminator = np.zeros(2 * batch_size)\n",
    "        y_discriminator[:batch_size] = 0.9  # Label smoothing\n",
    "\n",
    "        discriminator_loss = discriminator.train_on_batch(Xy, y_discriminator)\n",
    "\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, 50))\n",
    "        y_gan = np.ones(batch_size)\n",
    "        gan_loss = gan.train_on_batch(noise, y_gan)\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss}, GAN Loss: {gan_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 773us/step\n"
     ]
    }
   ],
   "source": [
    "# Generating the new data with labels\n",
    "num_synthetic_samples = 1000\n",
    "noise = np.random.normal(0, 1, size=(num_synthetic_samples, 50))\n",
    "synthetic_samples = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32345915, -0.47504732,  1.70821   , ..., -2.2538948 ,\n",
       "        -1.497531  , -2.2600029 ],\n",
       "       [ 0.24176769, -0.17335233,  1.2272843 , ..., -2.0606976 ,\n",
       "        -0.9735132 , -2.2675252 ],\n",
       "       [ 0.02540219, -0.23192069,  0.9667895 , ..., -1.878648  ,\n",
       "        -0.80007035, -1.8910781 ],\n",
       "       ...,\n",
       "       [ 0.31821173, -0.83303046,  1.1491485 , ..., -1.8884203 ,\n",
       "        -1.018875  , -1.4994751 ],\n",
       "       [-0.06323391, -0.25735375,  0.78762186, ..., -0.9178278 ,\n",
       "        -0.8579634 , -1.3415406 ],\n",
       "       [-0.23944673, -0.45586166,  1.0438039 , ..., -2.2090416 ,\n",
       "        -1.2579383 , -1.8022774 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8) (100,)\n"
     ]
    }
   ],
   "source": [
    "X_small = X[:100, :]\n",
    "y_small = y[:100]\n",
    "\n",
    "print(X_small.shape, y_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_small,\n",
    "                                                    y_small,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.24338957249433815\n"
     ]
    }
   ],
   "source": [
    "y_pred = regression_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model on (original+generated) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_X = synthetic_samples[:100, :8]\n",
    "generated_y = synthetic_samples[:100, 8:].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X = np.concatenate([X_small, generated_X], axis=0)\n",
    "combined_y = np.concatenate([y_small, generated_y], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(combined_X,\n",
    "                                                            combined_y,\n",
    "                                                            test_size=0.2,\n",
    "                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_regression_model = LinearRegression()\n",
    "new_regression_model.fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.12584670369745898\n"
     ]
    }
   ],
   "source": [
    "y_pred_c = new_regression_model.predict(X_test_c)\n",
    "\n",
    "mse = mean_squared_error(y_test_c, y_pred_c)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "We can see that when we add the generated data from the GAN, it makes the loss better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
